#!/usr/bin/env python
# -*- coding: utf-8 -*-
import numpy as np
import h5py
from optparse import OptionParser
import os
import sys
from astropy.io import fits
import vaex.dataset



usage = """
Convert comma seperate value format to hdf5 format:

Example:

vaex-data-csv2hdf5 $vaex_DATA/rave_internal_300808.v1g.TJK.uniform.final.post.csv -o rave.hdf5

"""
parser = OptionParser(usage=usage)

#parser.add_option("-n", "--name",
 #                 help="dataset name [default=%default]", default="data", type=str)
parser.add_option("-o", "--output",
                 help="dataset output filename [by default the suffix of input filename will be replaced by hdf5]", default=None, type=str)
parser.add_option("-s", "--seperator",
                 help="column seperator [default=%default", default=",", type=str)
parser.add_option("-a", "--all", action="store_true", default=False, help="export all columns")
parser.add_option("--no-header", dest="header", action="store_false", default=True, help="do not write out a column")
(options, args) = parser.parse_args()

	
	
	
h5filename = args[0]
if options.output is None:
	basename = os.path.splitext(h5filename)[0]
	fitsfilename = basename + ".fits"
else:
	fitsfilename = options.output
	
#if 0:
#	print >>sys.stderr, "opening:", h5filename
	#h5file = h5py.File(h5filename, "r") #, driver="core")
	#data = h5file["data"]

dataset = vaex.dataset.Hdf5MemoryMapped(h5filename)

if options.all:
	column_names = dataset.column_names
elif (len(args) == 1) and not options.all:
	print "add column names after filename or use -a/--all for all"
	print "possible column names: [%s]:" % ",".join([str(k) for k in dataset.column_names])
	sys.exit(1)
else:
	column_names = map(str, args[1:])


print >>sys.stderr, "writing to:", fitsfilename

columns = []
formats = {np.float64:"D"}

for column_name in column_names:
	column = dataset.columns[column_name]
	if column.dtype.type not in formats:
		print "don't know what to do with column type", column.dtype
	else:
		print repr(column.dtype)
		format = formats[column.dtype.type]
		arr = np.array(column)
		print column.dtype.type, format, arr.dtype
		fits_col = fits.Column(name=column_name, format=format, array=arr)
		columns.append(fits_col)
		print fits_col.array.dtype.isnative


cols = fits.ColDefs(columns)
tbhdu = fits.new_table(cols)
#tbhdu = fits.BinTableHDU.from_columns(cols)
n = np.zeros(10)
hdu = fits.PrimaryHDU(n)


prihdr = fits.Header()
prihdr['COMMENT'] = "Generated with vaex"
prihdu = fits.PrimaryHDU(header=prihdr)

thdulist = fits.HDUList([prihdu, tbhdu])
thdulist.writeto(fitsfilename)


if 0:
	#data = np.genfromtxt(csvfilename, delimiter=',', dtype=None, names=True)
	#print "columns:", data.dtype.names
	#print np.mean(data["Vr"])
						
	print >>sys.stderr, "writing to:", csvfilename

	f = file(csvfilename, "w")

	#column_names = data.keys()
	if options.header:
		print >>f, options.seperator.join(column_names)

	N = len(h5file["data"][column_names[0]])
	print >>sys.stderr, "number of rows: %d" % N

	datamap = dict([(column_name, np.array(h5file["data"][column_name])) for column_name in column_names])

	for i in range(N):
		values = [datamap[column_name][i] for column_name in column_names]
		print >>f, options.seperator.join(map(str,values))
#datagroup = h5file.create_group("data")
#for name, group in h5file["data"]
	
	#if name not in "OBJECT_ID":
	#if data[name].dtype.kind == "f":
	#	datagroup.create_dataset(name, data=data[name])
		
